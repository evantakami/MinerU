import os
import logging
import pandas as pd
import tiktoken
import time
import threading
import openpyxl
import json
from openpyxl.styles import Font, Alignment, PatternFill
from openpyxl.utils import get_column_letter
from excel_to_markdown import process_excel_file
import gradio as gr
from langchain.chat_models import AzureChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.output_parsers import StructuredOutputParser
from langchain.schema import HumanMessage, ResponseSchema
import zipfile
import re
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field
from langchain.output_parsers import OutputFixingParser

logging.basicConfig(
    filename="process.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    encoding="utf-8"
)


MODEL_CONFIG = {
    "GPT3.5": {
        "deployment_name": "gpt3.5-deployment",
        "input_cost": 0.000002,
        "output_cost": 0.000002
    },
    "4omini": {
        "deployment_name": "den-share-openai-gpt4o-mini",
        "input_cost": 0.000005,
        "output_cost": 0.000005
    }
}

os.environ["OPENAI_API_TYPE"] = "azure"
os.environ["OPENAI_API_KEY"] = "your_api_key"
os.environ["OPENAI_API_BASE"] = "your_api_base"
os.environ["OPENAI_API_VERSION"] = "your_api_version"

def count_tokens(text, model="gpt-4o-mini"):
    try:
        enc = tiktoken.encoding_for_model(model)
    except Exception:
        enc = tiktoken.get_encoding("cl100k_base")
    return len(enc.encode(text))

first_log_done = False
first_log_lock = threading.Lock()

def safe_to_excel(val):
    if isinstance(val, (dict, list)):
        try:
            return json.dumps(val, ensure_ascii=False)
        except Exception:
            return str(val)
    return val



template_stage1 = """
あなたは文書チェックの専門家です。以下のドキュメントをチェックし、問題があるかどうかを判断してください。

## チェック項目の詳細
項番: {item_no}
種別: {type_main}
種類: {type_sub}
確認内容: {check_item}
詳細指示: {detailed_instruction}
実施例及び注意観点: {example_and_points}
手順作成者コメント: {creator_comment}

## 文書内容
{document}

## チェック手順
STEP 1: チェック項目の要件を理解する
- 確認内容、詳細指示、実施例及び注意観点を詳細に分析し、何をチェックする必要があるかを明確にしてください。

STEP 2: 文書内容を分析する
- 文書の内容を詳細に読み、チェック項目と照らし合わせて分析してください。
- チェック項目に関連する部分を特定してください。

STEP 3: 問題点を特定する
- チェック項目の要件に照らして、文書内に問題点や改善が必要な箇所を見つけてください。
- 良い点も明確にしてください。

STEP 4: 詳細な評価を提供する
- チェック項目に関する評価を具体的に記述してください。
- 文書内の該当箇所を引用し、なぜ問題があるか、またはなぜ良いかを説明してください。
- 問題点がある場合は、どのように修正すべきかを具体的に提案してください。

## 出力形式
- 評価結果を数字の箇条書きで提供してください。
- 各項目には、問題点の説明とその理由、および改善提案（必要な場合）を含めてください。
- プレインテキストで提供してください。Markdownを使用しないでください。

例：
1. [具体的な問題点や良い点] - [理由] - [改善提案（必要な場合）]
2. [具体的な問題点や良い点] - [理由] - [改善提案（必要な場合）]
3. [具体的な問題点や良い点] - [理由] - [改善提案（必要な場合）]
"""

prompt_stage1 = PromptTemplate(
    input_variables=[
        "item_no",
        "type_main", 
        "type_sub", 
        "check_item", 
        "detailed_instruction",
        "example_and_points",
        "creator_comment", 
        "document"
    ],
    template=template_stage1
)



# Stage2用のスキーマ定義と解析器の設定（OK/NG判定用）
response_schemas_stage2 = [
    ResponseSchema(name="AI評価", description="評価結果。必ず「OK」または「NG」のいずれかの値を使用してください。それ以外の値は使用しないでください。"),
    ResponseSchema(name="改善案", description="NGの項目に対する修正提案。OKの場合は空白。絶対にJSON形式で提供しないでください。必ずplain textで提供してください。リスト、配列、オブジェクト形式は避けてください。")
]

output_parser_stage2 = StructuredOutputParser.from_response_schemas(response_schemas_stage2)
format_instructions_stage2 = output_parser_stage2.get_format_instructions()

template_stage2 = """あなたはチェック結果を判定する専門評価者です。

## チェックの対象
以下の手順書を参照してください: 
{document}

## あなたのタスク
以下のAI評価コメントに基づいて、チェック項目の最終評価と改善案を提供することです。

## AI評価コメント
{ai_comment}

## 評価手順
STEP 1: AI評価コメントを詳細に分析する
- AI評価コメントの内容を注意深く読み、手順書の問題点と良い点を特定してください。
- コメント内の具体的な指摘事項と理由を把握してください。

STEP 2: 判定を行う
- AI評価コメントに基づいて、以下のいずれかの判定を行ってください：
  [OK] - チェック項目の要件を満たしている場合
  [NG] - チェック項目の要件を満たしていない、または重要な問題がある場合

STEP 3: 改善案を作成する（NGの場合のみ）
- [NG]と判定した場合、AI評価コメントに基づいて具体的な改善案を提案してください。
- 手順書のどの部分をどのように修正すべきかを明確に示してください。
- 項番と具体的な修正内容を記載してください。

## 出力形式
AI評価: [OK] または [NG]

改善案: 
（[NG]の場合のみ記入）
項番：手順書の項番（例：2.0）
修正内容：具体的な修正案

---
重要：
- 「OK」に対しては改善案を提供しなくてよいです。
- 改善案は必ずPlain Textで提供してください。
- 絶対にJSON形式を使用しないでください。
- 改善案をリスト形式や配列形式で提供しないでください。
- プロパティ名やキー名を含めないでください。

{format_instructions_stage2}
"""

prompt_stage2 = PromptTemplate(
    input_variables=["ai_comment", "document"],
    partial_variables={"format_instructions_stage2": format_instructions_stage2},
    template=template_stage2
)

# Stage0用のスキーマ定義と解析器の設定（前処理チェック用）
pre_check_response_schemas = [
    ResponseSchema(name="項目ID", description="チェック項目の項番"),
    ResponseSchema(name="対象判定", description="「対象」または「対象外」のいずれか"),
    ResponseSchema(name="理由", description="対象外の場合、その理由を簡潔に説明。対象の場合は空欄")
]

output_parser_stage0 = StructuredOutputParser.from_response_schemas(pre_check_response_schemas)
format_instructions_stage0 = output_parser_stage0.get_format_instructions()

template_stage0 = """
あなたは手順書チェックの前処理を行う専門家です。手順書の内容を分析し、各チェック項目が当該文書に対して適用可能かどうかを判断してください。

## 手順書内容
{document}

## チェック項目
{check_items}

## 評価手順
STEP 1: 手順書の内容を理解する
- 手順書の内容、目的、対象読者、および主な手順を理解してください。
- 手順書に含まれる主要な内容やテーマを特定してください（例：SQL操作、画面操作、システム設定など）。

STEP 2: 各チェック項目を分析する
- 各チェック項目の目的と要件を理解してください。
- チェック項目が手順書のどの部分に適用されるかを特定してください。

STEP 3: 適用可能性を判断する
- 以下の条件に基づいて、各チェック項目が手順書に適用可能かどうかを判断してください：
  1. 手順書に関連する内容が含まれているか（例：SQLのチェック項目に対して、手順書にSQLが含まれているか）
  2. チェック項目が手順書の種類や目的に関連しているか
  3. チェック項目が手順書の対象読者や使用状況に適切かどうか

STEP 4: 判定結果を提供する
- 各チェック項目について「対象」または「対象外」の判定を行ってください。
- 「対象外」と判断した場合は、その理由を簡潔に説明してください。

## 出力形式
各チェック項目について、以下の形式でJSONレスポンスを返してください：

{format_instructions_stage0}
"""

prompt_stage0 = PromptTemplate(
    input_variables=["document", "check_items"],
    partial_variables={"format_instructions_stage0": format_instructions_stage0},
    template=template_stage0
)

# Stage2Score用のスキーマ定義と解析器の設定（点数評価用）
score_response_schemas = [
    ResponseSchema(name="採点", description="1から5の整数で評価。必ず単一の数字で提供してください。"),
    ResponseSchema(name="評価理由", description="詳細な評価理由、得点と失点の両方を含める。必ずプレーンテキストで記述し、JSON形式やマークダウン形式は使用しないでください。"),
    ResponseSchema(name="改善案", description="点数が5点未満の場合の具体的な改善提案。5点の場合は空白でも可。必ずプレーンテキストで記述し、JSON形式やマークダウン形式は絶対に使用しないでください。")
]

output_parser_stage2_score = StructuredOutputParser.from_response_schemas(score_response_schemas)
format_instructions_stage2_score = output_parser_stage2_score.get_format_instructions()

# 点数評価用のテンプレート
template_stage2_score = """あなたは手順書のチェック結果を採点する専門評価者です。

## あなたのタスク
あなたは、特定のチェック項目に関するAI評価コメントを分析し、手順書がこのチェック項目をどの程度満たしているかを5段階で採点してください。

## チェック項目の詳細
項番: {item_no}
種別: {type_main}
種類: {type_sub}
確認内容: {check_item}
詳細指示: {detailed_instruction}
実施例及び注意観点: {example_and_points}
手順作成者コメント: {creator_comment}

## AI評価コメント
{ai_comment}

## 手順書の参照情報
{document}

## 評価手順
STEP 1: チェック項目の要件を理解する
- 確認内容、詳細指示、実施例及び注意観点を詳細に分析し、このチェック項目が何を求めているかを理解してください。

STEP 2: AI評価コメントを分析する
- AI評価コメントが、チェック項目の要件に関してどのような指摘をしているかを分析してください。
- 手順書が要件を満たしている点と満たしていない点を区別してください。

STEP 3: 以下の評価基準に基づいて採点する
- 核心評価基準: 手順書がこのチェック項目の具体的な要件を満たしているか
  - 要件の適合度: チェック項目の具体的な要件に対して、手順書の内容がどの程度満たしているか
  - 指摘事項の重要度: AI評価コメントで指摘された問題の重要性と影響度

STEP 4: 総合的に5段階で評価する
5点: (非常に良い) このチェック項目の具体的な要件をすべて満たしており、改善の余地がほとんどない
4点: (良い) このチェック項目の具体的な要件をほぼ満たしているが、軽微な不足がある
3点: (普通) このチェック項目の基本的な要件は満たしているが、いくつかの不足がある
2点: (不十分) このチェック項目の重要な要件を満たしておらず、大幅な改善が必要
1点: (非常に不十分) このチェック項目の要件をほとんど満たしておらず、根本的な見直しが必要

STEP 5: 評価理由と改善案を詳細に説明する
- 評価の根拠となるAI評価コメントの内容を引用して説明してください
- 得点と失点の両方の理由を説明してください
- 点数が5点未満の場合は、このチェック項目を満たすための具体的な改善案を提案してください

## 出力形式
採点: [1-5の整数]
評価理由: [詳細な評価理由、得点と失点の両方を含める。AI評価コメントの具体的な内容を引用して説明]
改善案: [点数が5点未満の場合、このチェック項目を満たすための具体的な改善提案]

重要：
- 採点は必ず1から5の単一の数字で提供してください。
- 評価理由と改善案は必ずプレーンテキストで記述してください。
- 絶対にJSON形式やマークダウン形式を使用しないでください。
- キーや値のペアとしての記述（"評価理由": "..."）は使用しないでください。
- プロパティ名やキー名を含めないでください。

{format_instructions_stage2_score}
"""

# 点数評価用のプロンプト設定
prompt_stage2_score = PromptTemplate(
    input_variables=["ai_comment", "document", "item_no", "type_main", "type_sub", "check_item", "detailed_instruction", "example_and_points", "creator_comment"],
    partial_variables={"format_instructions_stage2_score": format_instructions_stage2_score},
    template=template_stage2_score
)

def pre_process_check_items(doc_text, items, llm_instance, selected_model):
    # 事前に対象外と判定する項目リスト
    pre_excluded_items = ["1", "2", "3", "5", "6"]
    
    # 事前チェック結果の初期化
    pre_check_results = []
    
    # トークン数の初期化
    pre_tokens_input = 0
    pre_tokens_output = 0
    
    # 事前に対象外と判定する項目を処理
    for item in items:
        item_no = item.get("項番", "")
        # 項目IDを文字列に変換
        item_no = str(item_no)
        # 項目IDを正規化
        normalized_id = item_no.split(".")[0] if "." in item_no else item_no
        
        # 正規化した項目IDと元の項目IDの両方をチェック
        if item_no in pre_excluded_items or normalized_id in [i.split(".")[0] for i in pre_excluded_items]:
            pre_check_results.append({
                "項目ID": item_no,
                "対象判定": "対象外",
                "理由": "事前指定による対象外"
            })
            logging.info(f"項番 {item_no}(正規化:{normalized_id}): 事前指定により対象外と判定されました")
    
    # 残りの項目を通常のAIチェックで処理
    remaining_items = []
    for item in items:
        item_no = item.get("項番", "")
        # 項目IDを文字列に変換
        item_no = str(item_no)
        normalized_id = item_no.split(".")[0] if "." in item_no else item_no
        
        if (item_no not in pre_excluded_items and 
            normalized_id not in [i.split(".")[0] for i in pre_excluded_items]):
            remaining_items.append(item)
    
    if remaining_items:
        # 既存のAIチェック処理を実行
        check_items_text = json.dumps([{
            "項番": item.get("項番", ""),
            "種別": item.get("種別", ""),
            "種別_小": item.get("種別_小", ""),
            "確認内容": item.get("確認内容", ""),
            "実施例及び、注意観点など": item.get("実施例及び、注意観点など", ""),
            "手順作成者コメント": item.get("手順作成者コメント", ""),
            "詳細指示": item.get("詳細指示", "")
        } for item in remaining_items], ensure_ascii=False, indent=2)
        
        try:
            pre_check_prompt = prompt_stage0.format(
                document=doc_text,
                check_items=check_items_text
            )
            
            # プロンプトのトークン数を計算
            pre_tokens_input = count_tokens(pre_check_prompt, model=MODEL_CONFIG[selected_model]["deployment_name"])
            
            raw_output = llm_instance([HumanMessage(content=pre_check_prompt)]).content
            
            # 出力のトークン数を計算
            pre_tokens_output = count_tokens(raw_output, model=MODEL_CONFIG[selected_model]["deployment_name"])
            
            # LLMの応答をログに記録
            logging.info(f"事前チェック(Stage0)の結果: {raw_output}")
            
            # JSONの解析処理：様々な形式に対応
            try:
                # 配列形式のJSONを探す
                json_match = re.search(r'\[.*\]', raw_output, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                    ai_check_results = json.loads(json_str)
                    logging.info("JSON配列形式で正常に解析されました")
                else:
                    # オブジェクト形式のJSONを探す
                    json_obj_match = re.search(r'\{.*\}', raw_output, re.DOTALL)
                    if json_obj_match:
                        json_str = json_obj_match.group(0)
                        json_obj = json.loads(json_str)
                        # オブジェクトを配列形式に変換する処理
                        if isinstance(json_obj, dict):
                            if "項目ID" in json_obj:
                                # 単一オブジェクトの場合
                                ai_check_results = [json_obj]
                                logging.info("JSON単一オブジェクト形式で正常に解析されました")
                            else:
                                # 複数オブジェクトの可能性
                                ai_check_results = []
                                for key, value in json_obj.items():
                                    if isinstance(value, dict) and "項目ID" in value:
                                        ai_check_results.append(value)
                                logging.info(f"JSONオブジェクト形式で正常に解析されました（{len(ai_check_results)}項目）")
                        else:
                            # デフォルトパーサーを使用
                            ai_check_results = output_parser_stage0.parse(raw_output)
                            logging.info("デフォルトパーサーを使用して解析されました")
                    else:
                        # JSON形式が見つからない場合
                        ai_check_results = output_parser_stage0.parse(raw_output)
                        logging.info("JSON形式が見つからず、デフォルトパーサーを使用しました")
                        
                # 結果を配列形式に統一
                if not isinstance(ai_check_results, list):
                    ai_check_results = [ai_check_results]
                
                # 結果の形式を検証
                valid_results = []
                for item in ai_check_results:
                    if isinstance(item, dict) and "項目ID" in item:
                        # 項目IDの正規化を確認
                        item_id = item["項目ID"]
                        if isinstance(item_id, (int, float)):
                            # 数値型をテキスト型に変換
                            item_id = str(int(item_id)) if item_id == int(item_id) else str(item_id)
                            item["項目ID"] = item_id
                            logging.info(f"項目ID {item_id} が数値型から文字列型に変換されました")
                        
                        valid_results.append(item)
                    else:
                        logging.warning(f"無効な形式の項目がスキップされました: {item}")
                
                ai_check_results = valid_results
                logging.info(f"抽出されたチェック結果: {json.dumps(ai_check_results, ensure_ascii=False)}")
                
                # 事前に除外した項目と合わせる
                pre_check_results.extend(ai_check_results)
                
            except Exception as parse_error:
                logging.error(f"JSON解析でエラーが発生しました: {parse_error}")
                logging.error(f"APIレスポンス: {raw_output}")
                
                # JSON解析失敗時の処理（残りの項目を対象外として処理）
                for item in remaining_items:
                    item_no = item.get("項番", "")
                    pre_check_results.append({
                        "項目ID": item_no,
                        "対象判定": "対象",  # エラー時はデフォルトで対象とする
                        "理由": ""
                    })
                logging.info(f"JSON解析エラーにより、残り{len(remaining_items)}項目をデフォルトで対象と自動判定しました")
            
        except Exception as e:
            logging.error(f"AIチェック処理でエラーが発生しました: {e}")
            # エラー発生時の処理（残りの項目を対象外として処理）
            for item in remaining_items:
                item_no = item.get("項番", "")
                pre_check_results.append({
                    "項目ID": item_no,
                    "対象判定": "対象",  # エラー時はデフォルトで対象とする
                    "理由": ""
                })
            logging.info(f"AIチェック処理エラーにより、残り{len(remaining_items)}項目をデフォルトで対象と自動判定しました")
            
            # エラー発生時のトークン処理
            if pre_tokens_input > 0:
                logging.info(f"エラー時のトークン数: 入力={pre_tokens_input}, 出力=0")
            else:
                pre_tokens_input = 0
                logging.info("エラー時のトークン数を計算できませんでした")
    
    # 対象外項目の件数をログに記録
    excluded_count = len([r for r in pre_check_results if r.get("対象判定") == "対象外"])
    target_count = len([r for r in pre_check_results if r.get("対象判定") == "対象"])
    logging.info(f"事前チェック完了: 合計{len(pre_check_results)}項目中、{excluded_count}項目が対象外、{target_count}項目が対象と判定されました")
    
    return pre_check_results, pre_tokens_input, pre_tokens_output

def process_check_item(item, doc_text, llm_instance, selected_model, evaluation_mode="OK/NG判定"):
    global first_log_done

    item_no = item.get("項番", "<no-id>")
    # 項目IDを文字列に変換
    item_no = str(item_no)
    type_main = str(item.get("種別", ""))
    type_sub = str(item.get("種別_小", ""))
    check_item_text = str(item.get("確認内容", ""))
    example_and_points = str(item.get("実施例及び、注意観点など", ""))
    creator_comment = str(item.get("手順作成者コメント", ""))
    detailed_instruction = str(item.get("詳細指示", ""))

    try:
        comment_prompt = prompt_stage1.format(
            item_no=item_no,
            type_main=type_main,
            type_sub=type_sub,
            check_item=check_item_text,
            detailed_instruction=detailed_instruction,
            example_and_points=example_and_points,
            creator_comment=creator_comment,
            document=doc_text
        )
        ai_comment = llm_instance([HumanMessage(content=comment_prompt)]).content
        tokens_prompt1 = count_tokens(comment_prompt, model=MODEL_CONFIG[selected_model]["deployment_name"])
        tokens_response1 = count_tokens(ai_comment, model=MODEL_CONFIG[selected_model]["deployment_name"])

        with first_log_lock:
            if not first_log_done:
                logging.info("ユーザーのプロンプト内容: " + comment_prompt)
                logging.info("AIのコメント内容: " + ai_comment)
                first_log_done = True
    except Exception as e:
        logging.error(f"項番 {item_no}: ステージ1のコメント生成に失敗しました: {e}")
        return {
            "項番": item_no,
            "AI評価のコメント": f"エラー: {e}",
            "AI評価": "エラー",
            "改善案": f"エラー: {e}",
            "input_tokens": 0,
            "output_tokens": 0,
            "total_tokens": 0
        }

    try:
        # 評価モードによって使用するテンプレートとパーサーを切り替え
        if evaluation_mode == "点数判定(1-5点)":
            result_prompt = template_stage2_score.format(
                ai_comment=ai_comment, 
                document=doc_text,
                item_no=item_no,
                type_main=type_main,
                type_sub=type_sub,
                check_item=check_item_text,
                detailed_instruction=detailed_instruction,
                example_and_points=example_and_points,
                creator_comment=creator_comment
            )
            raw_output = llm_instance([HumanMessage(content=result_prompt)]).content
            
            # 原始応答内容を記録
            logging.info(f"項番 {item_no}: 点数評価のLLM応答：{raw_output}")
            
            try:
                fixing_parser = OutputFixingParser.from_llm(parser=output_parser_stage2_score, llm=llm_instance)
                parsed_output = fixing_parser.parse(raw_output)
                ai_hyouka = parsed_output.get("採点", "")
                hyouka_reason = parsed_output.get("評価理由", "")
                kaizen = parsed_output.get("改善案", "")
                
                # JSON形式のチェックと修正
                if isinstance(hyouka_reason, dict) or hyouka_reason.startswith("{") or hyouka_reason.startswith("["):
                    logging.warning(f"項番 {item_no}: 評価理由がJSON形式で返されました。プレーンテキストに変換します。")
                    try:
                        # JSON形式の場合、内容を抽出
                        if isinstance(hyouka_reason, dict):
                            hyouka_reason = json.dumps(hyouka_reason, ensure_ascii=False)
                        hyouka_reason = "JSON形式が検出されました。内容：" + hyouka_reason
                    except Exception:
                        pass
                
                if isinstance(kaizen, dict) or (kaizen and (kaizen.startswith("{") or kaizen.startswith("["))):
                    logging.warning(f"項番 {item_no}: 改善案がJSON形式で返されました。プレーンテキストに変換します。")
                    try:
                        # JSON形式の場合、内容を抽出
                        if isinstance(kaizen, dict):
                            kaizen = json.dumps(kaizen, ensure_ascii=False)
                        kaizen = "JSON形式が検出されました。内容：" + kaizen
                    except Exception:
                        pass
                
                # AI評価と改善案を結合して保存（Excelの同じ列に表示するため）
                ai_hyouka = f"{ai_hyouka}点"
                kaizen = f"【評価理由】\n{hyouka_reason}\n\n【改善案】\n{kaizen}" if kaizen else f"【評価理由】\n{hyouka_reason}"
                
                logging.info(f"項番 {item_no}: 点数評価解析成功（評価: {ai_hyouka}）")
            except Exception as fix_error:
                logging.error(f"項番 {item_no}: 点数評価の解析に失敗しました: {fix_error}")
                # 正規表現で点数を抽出
                score_match = re.search(r'採点: (\d+)', raw_output)
                ai_hyouka = f"{score_match.group(1)}点" if score_match else "解析エラー"
                
                # 評価理由と改善案を抽出
                reason_match = re.search(r'評価理由: (.+?)(?=改善案:|$)', raw_output, re.DOTALL)
                improve_match = re.search(r'改善案: (.+?)(?=$)', raw_output, re.DOTALL)
                
                hyouka_reason = reason_match.group(1).strip() if reason_match else "解析エラー"
                improve_text = improve_match.group(1).strip() if improve_match else ""
                
                kaizen = f"【評価理由】\n{hyouka_reason}\n\n【改善案】\n{improve_text}" if improve_text else f"【評価理由】\n{hyouka_reason}"
        else:
            # 既存のOK/NG判定処理
            result_prompt = template_stage2.format(ai_comment=ai_comment, document=doc_text)
            raw_output = llm_instance([HumanMessage(content=result_prompt)]).content
            
            # 原始応答内容を記録
            logging.info(f"項番 {item_no}: ステージ2のLLM応答：{raw_output}")
            
            try:
                fixing_parser = OutputFixingParser.from_llm(parser=output_parser_stage2, llm=llm_instance)
                parsed_output = fixing_parser.parse(raw_output)
                ai_hyouka = parsed_output.get("AI評価", "")
                kaizen = parsed_output.get("改善案", "")
                
                # JSON形式のチェックと修正
                if isinstance(kaizen, dict) or (kaizen and (kaizen.startswith("{") or kaizen.startswith("["))):
                    logging.warning(f"項番 {item_no}: 改善案がJSON形式で返されました。プレーンテキストに変換します。")
                    try:
                        # JSON形式の場合、内容を抽出
                        if isinstance(kaizen, dict):
                            kaizen = json.dumps(kaizen, ensure_ascii=False)
                        kaizen = "JSON形式が検出されました。内容：" + kaizen
                    except Exception:
                        pass
                
                logging.info(f"項番 {item_no}: 出力修正解析成功（評価: {ai_hyouka}）")
            except Exception as fix_error:
                logging.error(f"項番 {item_no}: 出力修正解析にも失敗しました: {fix_error}")
                # 以下は代替解析方法として残しておく
                try:
                    parsed_output = output_parser_stage2.parse(raw_output)
                    ai_hyouka = parsed_output.get("AI評価", "")
                    kaizen = parsed_output.get("改善案", "")
                    logging.info(f"項番 {item_no}: 構造化解析成功（評価: {ai_hyouka}）")
                except Exception as parse_error:
                    logging.error(f"項番 {item_no}: 構造化解析に失敗しました: {parse_error}")
                    # 代替解析方法としてregexを使用
                    ai_hyouka_match = re.search(r'\[OK\]|\[NG\]', raw_output)
                    ai_hyouka = ai_hyouka_match.group(0).strip('[]') if ai_hyouka_match else "解析エラー"
                    
                    if "改善案" in raw_output:
                        kaizen_parts = raw_output.split("改善案", 1)
                        kaizen = kaizen_parts[1].strip() if len(kaizen_parts) > 1 else "解析エラー"
                    else:
                        kaizen = "解析エラー"
        
        tokens_prompt2 = count_tokens(result_prompt, model=MODEL_CONFIG[selected_model]["deployment_name"])
        tokens_response2 = count_tokens(raw_output, model=MODEL_CONFIG[selected_model]["deployment_name"])
    except Exception as e:
        logging.error(f"項番 {item_no}: ステージ2の評価生成に失敗しました: {e}")
        ai_hyouka = "エラー"
        kaizen = f"エラー: {e}"
        tokens_prompt2 = 0
        tokens_response2 = 0

    input_tokens = tokens_prompt1 + tokens_prompt2
    output_tokens = tokens_response1 + tokens_response2
    total_tokens = input_tokens + output_tokens

    return {
        "項番": item_no,
        "AI評価のコメント": ai_comment,
        "AI評価": ai_hyouka,
        "改善案": kaizen,
        "input_tokens": input_tokens,
        "output_tokens": output_tokens,
        "total_tokens": total_tokens
    }

def process_uploaded_file(uploaded_excel_file, selected_types, selected_model, llm_instance, evaluation_mode="OK/NG判定"):
    try:
        if isinstance(uploaded_excel_file, dict):
            file_name = uploaded_excel_file["name"]
            file_data = uploaded_excel_file["data"]
            os.makedirs("uploads", exist_ok=True)
            upload_path = os.path.join("uploads", file_name)
            with open(upload_path, "wb") as f:
                f.write(file_data)
        elif hasattr(uploaded_excel_file, "read"):
            file_name = os.path.basename(uploaded_excel_file.name)
            os.makedirs("uploads", exist_ok=True)
            upload_path = os.path.join("uploads", file_name)
            with open(upload_path, "wb") as f:
                f.write(uploaded_excel_file.read())
        else:
            file_name = os.path.basename(uploaded_excel_file)
            upload_path = uploaded_excel_file

        logging.info(f"ファイル '{file_name}' の処理を開始します")
        logging.info(f"使用モデル: {selected_model}")
        logging.info(f"評価モード: {evaluation_mode}")
        if selected_types:
            logging.info(f"選択された種別: {', '.join(selected_types)}")
        else:
            logging.info("種別の選択なし: すべての種別が対象")

        process_excel_file(upload_path)
        logging.info(f"Excelファイルをマークダウンに変換しました: {upload_path}")

        md_folder = os.path.join(os.path.dirname(upload_path), os.path.splitext(file_name)[0])
        if not os.path.exists(md_folder):
            error_msg = "Markdownファイルへの変換に失敗しました。フォルダが存在しません。"
            logging.error(error_msg)
            return error_msg, None

        csv_file = "check_list.csv"
        df = pd.read_csv(csv_file, encoding="utf-8-sig")
        items = df.to_dict(orient="records")
        logging.info(f"チェックリストを読み込みました: {len(items)}項目")
        
        # チェックリストの項番フォーマットを記録（デバッグ用）
        item_nos = [item.get("項番", "<no-id>") for item in items]
        logging.info(f"チェックリストの項番一覧: {item_nos[:10]}... (最初の10項目のみ表示)")

        md_files = [f for f in os.listdir(md_folder) if f.lower().endswith(".md")]
        if not md_files:
            error_msg = "変換後のフォルダにMarkdownファイルがありません。"
            logging.error(error_msg)
            return error_msg, None
        logging.info(f"変換されたマークダウンファイル: {len(md_files)}個")

        template_excel = "F-0168-2.xlsx"
        wb = openpyxl.load_workbook(template_excel)
        template_sheet_name = "商用作業手順書チェックリスト"
        if template_sheet_name not in wb.sheetnames:
            return f"テンプレートシート[{template_sheet_name}]が存在しません。", None
        template_sheet = wb[template_sheet_name]

        results_dict = {}
        cost_summary = {}

        for md_filename in md_files:
            md_path = os.path.join(md_folder, md_filename)
            logging.info(f"マークダウンファイル '{md_filename}' の処理を開始します")
            
            with open(md_path, "r", encoding="utf-8") as f:
                doc_text = f.read()  # ファイル内容を読み込む
            logging.info(f"マークダウンファイルの内容を読み込みました: {len(doc_text)}文字")

            # 事前チェックを実行
            logging.info(f"事前チェック(Stage0)を開始します: {len(items)}項目を評価")
            pre_check_results, pre_tokens_input, pre_tokens_output = pre_process_check_items(doc_text, items, llm_instance, selected_model)
            logging.info(f"事前チェック(Stage0)が完了しました: 入力tokens={pre_tokens_input}, 出力tokens={pre_tokens_output}")
            
            # 事前チェック結果のデバッグ出力
            logging.info(f"事前チェック結果の詳細: {json.dumps(pre_check_results[:5], ensure_ascii=False)} (最初の5項目のみ表示)")
            
            # 事前チェック結果をディクショナリに変換（項目IDをキーとする）
            pre_check_dict = {}
            
            # 事前チェック結果をログに記録
            logging.info(f"事前チェック結果: {len(pre_check_results)}項目が処理されました")
            
            # 結果をディクショナリに変換（項目IDをキーとする）
            if pre_check_results:
                for result in pre_check_results:
                    item_id = result.get("項目ID", "")
                    if not item_id:
                        logging.warning("項目IDがない事前チェック結果があります")
                        continue
                    
                    # 項目IDを文字列に変換
                    item_id = str(item_id)
                    
                    # 項目IDを正規化（書式の違いを吸収する）
                    # 例："1.0" と "1" を同じキーとして扱う
                    normalized_id = item_id.split(".")[0] if "." in item_id else item_id
                    
                    pre_check_dict[normalized_id] = {
                        "対象判定": result.get("対象判定", ""),
                        "理由": result.get("理由", "")
                    }
                    
                    # 元のIDでも保存（念のため）
                    pre_check_dict[item_id] = pre_check_dict[normalized_id]
                    
                    # 対象外項目をログに記録
                    if result.get("対象判定") == "対象外":
                        logging.info(f"項番 {item_id}(正規化:{normalized_id}): 事前チェックにより対象外と判定されました（理由: {result.get('理由', '該当なし')}）")
            else:
                logging.warning("事前チェック結果が空です。すべての項目が対象として処理されます。")
                
            # ディクショナリのキー一覧を出力（デバッグ用）
            pre_check_keys = list(pre_check_dict.keys())
            logging.info(f"事前チェック結果のキー一覧: {pre_check_keys[:10]}... (最初の10項目のみ表示)")

            # 処理統計の初期化
            processed_count = 0
            skipped_count = 0
            file_results = []
            total_input_tokens = pre_tokens_input
            total_output_tokens = pre_tokens_output

            # 処理対象項目と対象外項目を分ける
            target_items = []
            skipped_items = []
            
            # 項目ID不一致の問題を検出するための変数
            missing_ids = []
            
            for item in items:
                item_no = item.get("項番", "<no-id>")
                # 項目IDを文字列に変換
                item_no = str(item_no)
                # 項目番号の正規化
                normalized_no = item_no.split(".")[0] if "." in item_no else item_no
                
                # 対象外判定条件を確認
                is_excluded = False
                exclusion_reason = ""
                
                # 1. 種別選択による除外
                if selected_types and item.get("種別", "") not in selected_types:
                    is_excluded = True
                    exclusion_reason = "チェック対象外（種別選択による除外）"
                    logging.info(f"項番 {item_no}: 種別選択により対象外と判定されました")
                
                # 2. 事前チェックによる除外
                elif item_no in pre_check_dict:
                    judgement = pre_check_dict[item_no].get("対象判定", "")
                    if judgement == "対象外":
                        is_excluded = True
                        exclusion_reason = f"チェック対象外: {pre_check_dict[item_no].get('理由', '該当なし')}"
                        logging.info(f"項番 {item_no}: 事前チェックにより対象外と判定されました（判定: {judgement}）")
                    elif judgement == "対象":
                        logging.info(f"項番 {item_no}: 事前チェックにより対象と判定されました")
                # 3. 正規化したIDで検索
                elif normalized_no in pre_check_dict:
                    judgement = pre_check_dict[normalized_no].get("対象判定", "")
                    if judgement == "対象外":
                        is_excluded = True
                        exclusion_reason = f"チェック対象外: {pre_check_dict[normalized_no].get('理由', '該当なし')}"
                        logging.info(f"項番 {item_no}(正規化:{normalized_no}): 事前チェックにより対象外と判定されました（判定: {judgement}）")
                    elif judgement == "対象":
                        logging.info(f"項番 {item_no}(正規化:{normalized_no}): 事前チェックにより対象と判定されました")
                # 4. 前方一致検索（例："1"で"1.0"を検索）
                else:
                    found = False
                    for key in pre_check_dict.keys():
                        if key.startswith(normalized_no + ".") or key == normalized_no:
                            judgement = pre_check_dict[key].get("対象判定", "")
                            if judgement == "対象外":
                                is_excluded = True
                                exclusion_reason = f"チェック対象外: {pre_check_dict[key].get('理由', '該当なし')}"
                                logging.info(f"項番 {item_no}(前方一致:{key}): 事前チェックにより対象外と判定されました（判定: {judgement}）")
                            elif judgement == "対象":
                                logging.info(f"項番 {item_no}(前方一致:{key}): 事前チェックにより対象と判定されました")
                            found = True
                            break
                    
                    if not found:
                        missing_ids.append(item_no)
                        logging.warning(f"項番 {item_no}: 事前チェック結果が見つかりません。デフォルトで対象として処理します。")
                
                # 処理対象/対象外の振り分け
                if is_excluded:
                    skipped_items.append({
                        "item": item,
                        "reason": exclusion_reason
                    })
                else:
                    target_items.append(item)
                    if not is_excluded and item_no not in missing_ids:
                        logging.info(f"項番 {item_no}: 処理対象として判定されました")
            
            # 事前チェック結果との照合結果の統計
            logging.info(f"処理対象: {len(target_items)}項目, 対象外: {len(skipped_items)}項目")
            logging.info(f"事前チェック結果不一致: {len(missing_ids)}項目 (項目ID: {missing_ids[:5]}...)")
            
            # 対象外項目の処理（API呼び出し不要）
            for skipped_item in skipped_items:
                item = skipped_item["item"]
                item_no = item.get("項番", "<no-id>")
                reason = skipped_item["reason"]
                
                result = {
                    "項番": item_no,
                    "AI評価のコメント": reason,
                    "AI評価": "対象外",
                    "改善案": "",
                    "input_tokens": 0,
                    "output_tokens": 0,
                    "total_tokens": 0
                }
                file_results.append(result)
                skipped_count += 1
            
            # 対象項目の処理（API呼び出し必要）
            for item in target_items:
                item_no = item.get("項番", "<no-id>")
                logging.info(f"項番 {item_no}: 処理を開始します")
                
                # 対象となる項目は通常処理
                result = process_check_item(item, doc_text, llm_instance, selected_model, evaluation_mode)
                file_results.append(result)
                total_input_tokens += result.get("input_tokens", 0)
                total_output_tokens += result.get("output_tokens", 0)
                processed_count += 1
                
                # API制限を避けるための待機
                time.sleep(2)
            
            # 処理統計をログに記録
            logging.info(f"ファイル {md_filename} の処理統計: 処理項目数={processed_count}, スキップ項目数={skipped_count}")
            
            results_dict[md_filename] = file_results
            model_cost = MODEL_CONFIG.get(selected_model, {"input_cost": 0, "output_cost": 0})
            cost_input = total_input_tokens * model_cost["input_cost"]
            cost_output = total_output_tokens * model_cost["output_cost"]
            total_cost = cost_input + cost_output
            cost_summary[md_filename] = (total_input_tokens, total_output_tokens, total_cost)

            new_sheet = wb.copy_worksheet(template_sheet)
            new_sheet.title = os.path.splitext(md_filename)[0][:31]

            data_font = Font(name="Meiryo UI", size=10, bold=False)
            data_alignment = Alignment(horizontal="left", vertical="bottom")
            data_fill = PatternFill(fill_type="solid", fgColor="FFFFFF")
            start_row = 10
            start_col = 11

            # 按照項番排序
            def sort_key(item):
                item_no = str(item.get("項番", "0"))
                parts = item_no.split(".")
                # 处理形如"1.1"、"2.3"的項番格式
                try:
                    if len(parts) == 1:
                        return (int(parts[0]), 0)
                    elif len(parts) == 2:
                        return (int(parts[0]), int(parts[1]))
                    else:
                        # 处理多级項番，如"1.2.3"
                        return tuple(int(p) if p.isdigit() else 0 for p in parts)
                except ValueError:
                    # 如果無法解析為數字，則按字符串排序
                    return item_no
            
            # 對結果進行排序
            sorted_results = sorted(file_results, key=sort_key)
            logging.info(f"結果を項番順にソートしました: {len(sorted_results)}項目")

            for idx, result in enumerate(sorted_results):
                excel_row = start_row + idx

                ai_comment_val = safe_to_excel(result.get("AI評価のコメント", ""))
                ai_hyouka_val = safe_to_excel(result.get("AI評価", ""))
                kaizen_val = safe_to_excel(result.get("改善案", ""))

                cell = new_sheet.cell(row=excel_row, column=start_col)
                cell.value = ai_comment_val
                cell.font = data_font
                cell.alignment = data_alignment
                cell.fill = data_fill

                cell = new_sheet.cell(row=excel_row, column=start_col + 1)
                cell.value = ai_hyouka_val
                cell.font = data_font
                cell.alignment = data_alignment
                cell.fill = data_fill

                cell = new_sheet.cell(row=excel_row, column=start_col + 2)
                cell.value = kaizen_val
                cell.font = data_font
                cell.alignment = data_alignment
                cell.fill = data_fill

        wb.remove(template_sheet)
        output_excel = f"チェック結果_{os.path.splitext(file_name)[0]}.xlsx"
        wb.save(output_excel)

        summary = f"ファイル: {file_name}\nMarkdownフォルダ: {md_folder}\n"
        total_processed = 0
        total_skipped = 0
        total_all_tokens = 0
        total_all_cost = 0
        
        for md_filename, cost in cost_summary.items():
            # 対象ファイルの結果を取得
            file_results = results_dict[md_filename]
            # 処理済み項目と対象外項目をカウント
            processed = sum(1 for r in file_results if r.get("input_tokens", 0) > 0)
            skipped = len(file_results) - processed
            total_processed += processed
            total_skipped += skipped
            
            # トークン数とコスト計算
            tokens = cost[0] + cost[1]
            total_all_tokens += tokens
            cost_value = cost[2]
            total_all_cost += cost_value
            
            summary += f"  - {md_filename}: 処理項目={processed}, 対象外項目={skipped}, 入力tokens={cost[0]}, 出力tokens={cost[1]}, コスト=${cost_value:.6f}\n"
        
        # 合計の統計情報
        summary += f"\n合計統計:\n"
        summary += f"  - 処理項目数: {total_processed}\n"
        summary += f"  - 対象外項目数: {total_skipped}\n"
        summary += f"  - 合計tokens: {total_all_tokens}\n"
        summary += f"  - 合計コスト: ${total_all_cost:.6f}\n"
        summary += f"\n作成されたExcelファイル: {output_excel}\n"
        
        logging.info(f"ファイル '{file_name}' の処理が完了しました")
        return summary, output_excel

    except Exception as e:
        return f"処理中にエラーが発生しました: {e}", None

def process_uploaded_files(uploaded_excel_files, selected_types, selected_model, llm_instance, evaluation_mode="OK/NG判定"):
    all_summaries = []
    generated_excels = []

    if not isinstance(uploaded_excel_files, list):
        uploaded_excel_files = [uploaded_excel_files]

    for file_data in uploaded_excel_files:
        summary, excel_path = process_uploaded_file(file_data, selected_types, selected_model, llm_instance, evaluation_mode)
        all_summaries.append(summary)
        if excel_path:
            generated_excels.append(excel_path)

    combined_summary = "\n\n".join(all_summaries)

    if not generated_excels:
        return combined_summary, None

    zip_name = "batch_results.zip"
    with zipfile.ZipFile(zip_name, "w", zipfile.ZIP_DEFLATED) as zf:
        for excel_file in generated_excels:
            arcname = os.path.basename(excel_file)
            zf.write(excel_file, arcname)
    return combined_summary, zip_name

def run_interface(uploaded_excel_files, selected_model, selected_types, evaluation_mode):
    try:
        config = MODEL_CONFIG.get(selected_model)
        if config is None:
            raise ValueError("選択されたモデルが無効です。")
        llm_instance = AzureChatOpenAI(
            deployment_name=config["deployment_name"],
            openai_api_base=os.environ["OPENAI_API_BASE"],
            openai_api_version=os.environ["OPENAI_API_VERSION"],
            openai_api_key=os.environ["OPENAI_API_KEY"],
            temperature=0
        )
        summary, zip_file = process_uploaded_files(uploaded_excel_files, selected_types, selected_model, llm_instance, evaluation_mode)
        return summary, zip_file
    except Exception as e:
        return f"全体処理中にエラーが発生しました: {e}", None

try:
    df_check = pd.read_csv("check_list.csv", encoding="utf-8-sig")
    types_options = df_check["種別"].dropna().unique().tolist()
except Exception as e:
    logging.error(f"チェックリストの読み込みに失敗しました: {e}")
    types_options = []

with gr.Blocks() as demo:
    gr.Markdown("## AI 手順書チェックツール (複数ファイル対応版)")
    with gr.Row():
        input_files = gr.Files(label="Excel ファイルをまとめてアップロード", file_types=[".xlsx", ".xlsm"])
    with gr.Row():
        model_selection = gr.Radio(choices=["GPT3.5", "4omini"], label="モデル選択", value="4omini")
        selected_types = gr.CheckboxGroup(choices=types_options, label="チェック項目の種別選択 (空欄なら全て対象)")
    with gr.Row():
        evaluation_mode = gr.Radio(choices=["OK/NG判定", "点数判定(1-5点)"], label="評価方式", value="OK/NG判定")
    with gr.Row():
        run_btn = gr.Button("処理開始")
    with gr.Row():
        output_message = gr.Textbox(label="処理情報", interactive=False, lines=15)
    with gr.Row():
        output_file = gr.File(label="結果の Zip ファイルをダウンロード", file_types=[".zip"])
    
    run_btn.click(fn=run_interface, inputs=[input_files, model_selection, selected_types, evaluation_mode], outputs=[output_message, output_file])

demo.launch()
